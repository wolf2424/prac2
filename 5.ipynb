{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7922fa9b",
   "metadata": {},
   "source": [
    "Write a program for pre-processing of a text document such as stop word removal,\n",
    "stemming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "142c38cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f867684",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\neelk\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\neelk\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\neelk\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5c3b04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_document = \"Text preprocessing is an essential step in natural language processing.\"\n",
    "words = word_tokenize(text_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c255777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Words: ['Text', 'preprocessing', 'essential', 'step', 'natural', 'language', 'processing', '.']\n"
     ]
    }
   ],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "print(\"Filtered Words:\", filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d373cd33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stemmed Words: ['text', 'preprocess', 'essenti', 'step', 'natur', 'languag', 'process', '.']\n"
     ]
    }
   ],
   "source": [
    "stemmer = PorterStemmer()\n",
    "stemmed_words = [stemmer.stem(word) for word in filtered_words]\n",
    "print(\"Stemmed Words:\", stemmed_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa9f70db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemmatized Words: ['Text', 'preprocessing', 'essential', 'step', 'natural', 'language', 'processing', '.']\n"
     ]
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatized_words = [lemmatizer.lemmatize(word) for word in filtered_words]\n",
    "print(\"Lemmatized Words:\", lemmatized_words)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "224985f6",
   "metadata": {},
   "source": [
    "Code Explanation\n",
    "Imports: The code imports essential modules from the nltk library.\n",
    "\n",
    "stopwords: For removing common, non-essential words (e.g., \"is,\" \"the\").\n",
    "word_tokenize: For splitting text into individual words (tokens).\n",
    "PorterStemmer: For stemming, which reduces words to their base form by removing suffixes (e.g., \"processing\" to \"process\").\n",
    "WordNetLemmatizer: For lemmatization, which reduces words to their dictionary base forms (e.g., \"better\" to \"good\").\n",
    "Downloading Resources:\n",
    "\n",
    "The nltk.download() commands download necessary resources:\n",
    "'stopwords': The list of English stopwords.\n",
    "'punkt': Tokenizer model.\n",
    "'wordnet': WordNet lexical database used for lemmatization.\n",
    "Text Processing:\n",
    "\n",
    "text_document is the input text.\n",
    "word_tokenize(text_document): Tokenizes the text, splitting it into individual words.\n",
    "stop_words: Fetches a list of English stopwords.\n",
    "filtered_words: Filters out any word that is a stopword. Words are converted to lowercase to ensure case-insensitive comparison.\n",
    "Stemming and Lemmatization:\n",
    "\n",
    "stemmer = PorterStemmer(): Initializes the stemmer.\n",
    "stemmed_words: Applies stemming to each filtered word, producing a list of stemmed words.\n",
    "lemmatizer = WordNetLemmatizer(): Initializes the lemmatizer.\n",
    "lemmatized_words: Applies lemmatization to each filtered word, producing a list of lemmatized words."
   ]
  },
  {
   "cell_type": "raw",
   "id": "dcd99299",
   "metadata": {},
   "source": [
    "What is text preprocessing, and why is it important?\n",
    "\n",
    "Answer: Text preprocessing is the process of transforming raw text into a clean and structured format for NLP tasks. It improves the accuracy and efficiency of NLP models by removing irrelevant parts and standardizing the text.\n",
    "\n",
    "What are stopwords, and why do we remove them?\n",
    "\n",
    "Answer: Stopwords are common words like \"the,\" \"is,\" and \"in\" that carry little meaning and add noise to NLP models. Removing them helps focus on the words that contribute more meaning to the text.\n",
    "\n",
    "What is the difference between stemming and lemmatization?\n",
    "\n",
    "Answer: Stemming reduces a word to its root form by removing suffixes, which may not always result in valid words. Lemmatization reduces a word to its base or dictionary form, considering the word's context, thus producing valid words.\n",
    "\n",
    "Why do we use lowercase conversion during stopword removal?\n",
    "\n",
    "Answer: Lowercase conversion ensures consistency, as \"The\" and \"the\" are treated as the same word, improving accuracy in stopword removal.\n",
    "\n",
    "What are some applications of tokenization in NLP?\n",
    "\n",
    "Answer: Tokenization splits text into words or sentences, which is essential for tasks like sentiment analysis, machine translation, and language modeling, where individual word meanings are analyzed."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
